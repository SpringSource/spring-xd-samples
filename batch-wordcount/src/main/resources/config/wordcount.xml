<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
	xmlns:hadoop="http://www.springframework.org/schema/hadoop"
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xmlns:batch="http://www.springframework.org/schema/batch"
	xmlns:context="http://www.springframework.org/schema/context"
	xmlns:util="http://www.springframework.org/schema/util"
	xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd
		http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util.xsd
		http://www.springframework.org/schema/hadoop http://www.springframework.org/schema/hadoop/spring-hadoop.xsd
		http://www.springframework.org/schema/batch http://www.springframework.org/schema/batch/spring-batch.xsd
		http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd">

	<context:property-placeholder properties-ref="myProperties" />

	<util:properties id="myProperties" >
		<prop key="wordcount.input.path">/count/in/</prop>
		<prop key="wordcount.output.path">/count/out/</prop>
		<prop key="hd.fs">hdfs://localhost:8020</prop>
	</util:properties>

	<hadoop:configuration>
		fs.default.name=${hd.fs}
	</hadoop:configuration>

	<!-- required since Hadoop Job is a class not an interface and we need to use a Job with step scope to access #{jobParameters['...']} -->
	<bean class="org.springframework.batch.core.scope.StepScope">
		<property name="proxyTargetClass" value="true"/>
	</bean>

	<batch:job id="job">
		<batch:step id="import" next="wordcount">
			<batch:tasklet ref="scriptTasklet"/>
		</batch:step>
		<batch:step id="wordcount">
			<batch:tasklet ref="wordcount-tasklet" />
		</batch:step>
	</batch:job>

	<hadoop:job-tasklet id="wordcount-tasklet" job-ref="wordcountJob"/>

	<hadoop:job id="wordcountJob"
		input-path="${wordcount.input.path}"
		output-path="${wordcount.output.path}"
		mapper="org.apache.hadoop.examples.WordCount$TokenizerMapper"
		reducer="org.apache.hadoop.examples.WordCount$IntSumReducer"
		scope="step" />
	<hadoop:script-tasklet id="scriptTasklet" script-ref="hdfsScript" scope="step"/>

	<hadoop:script id="hdfsScript" language="groovy" scope="step"><!-- file:///#{jobParameters['input.file.name']} -->
		<hadoop:property name="localSourceFile" value="${resources:file:///#{jobParameters['absoluteFilePath']}}"/>
		<hadoop:property name="hdfsInputDir" value="${wordcount.input.path}"/>
		<hadoop:property name="hdfsOutputDir" value="${wordcount.output.path}"/>
			//requires three variables, localSourceFile and hdfsInputDir, hdfsOutputDir
			// use the shell (made available under variable fsh)
			if (!fsh.test(hdfsInputDir)) {
				fsh.mkdir(hdfsInputDir);
				fsh.copyFromLocal(localSourceFile, hdfsInputDir);
				fsh.chmod(700, hdfsInputDir)
			}
			if (fsh.test(hdfsOutputDir)) {
				fsh.rmr(hdfsOutputDir)
			}
	</hadoop:script>

</beans>

